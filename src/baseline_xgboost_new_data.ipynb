{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33bd7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, RocCurveDisplay, ConfusionMatrixDisplay\n",
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format='svg'\n",
    "plt.rcParams.update({\n",
    "    'text.usetex':False\n",
    "})\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959fb4c",
   "metadata": {},
   "source": [
    "## Loading the dataset, pre-processing, and analysing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84da7975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>anion_gap_mean</th>\n",
       "      <th>anion_gap_sd</th>\n",
       "      <th>anion_gap_min</th>\n",
       "      <th>anion_gap_max</th>\n",
       "      <th>bicarbonate_mean</th>\n",
       "      <th>bicarbonate_sd</th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>bicarbonate_max</th>\n",
       "      <th>calcium_total_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>urea_nitrogen_min</th>\n",
       "      <th>urea_nitrogen_max</th>\n",
       "      <th>white_blood_cells_mean</th>\n",
       "      <th>white_blood_cells_sd</th>\n",
       "      <th>white_blood_cells_min</th>\n",
       "      <th>white_blood_cells_max</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>icu_los_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>67</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>F</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>291702</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239229</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>85</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212881</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30484</th>\n",
       "      <td>268219</td>\n",
       "      <td>18.473684</td>\n",
       "      <td>3.539254</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.552632</td>\n",
       "      <td>5.717197</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.582143</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>19.989744</td>\n",
       "      <td>12.016125</td>\n",
       "      <td>6.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "      <td>596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>223087</td>\n",
       "      <td>13.428571</td>\n",
       "      <td>3.207135</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.714286</td>\n",
       "      <td>1.496026</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.514286</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.272792</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>300</td>\n",
       "      <td>M</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>288516</td>\n",
       "      <td>21.745455</td>\n",
       "      <td>3.378681</td>\n",
       "      <td>16.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.309091</td>\n",
       "      <td>2.602511</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.477083</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>15.687755</td>\n",
       "      <td>6.906357</td>\n",
       "      <td>8.3</td>\n",
       "      <td>37.7</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>211323</td>\n",
       "      <td>18.972973</td>\n",
       "      <td>5.852286</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.621622</td>\n",
       "      <td>5.673287</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.229032</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>7.058621</td>\n",
       "      <td>2.703373</td>\n",
       "      <td>1.7</td>\n",
       "      <td>12.9</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>251051</td>\n",
       "      <td>24.545455</td>\n",
       "      <td>5.517038</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.053571</td>\n",
       "      <td>4.109500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.577778</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>16.906522</td>\n",
       "      <td>6.435506</td>\n",
       "      <td>7.5</td>\n",
       "      <td>31.9</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30489 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       icustay_id  anion_gap_mean  anion_gap_sd  anion_gap_min  anion_gap_max  \\\n",
       "0          217177             NaN           NaN            NaN            NaN   \n",
       "1          219934             NaN           NaN            NaN            NaN   \n",
       "2          291702       13.000000           NaN           13.0           13.0   \n",
       "3          239229       17.000000           NaN           17.0           17.0   \n",
       "4          212881       17.000000           NaN           17.0           17.0   \n",
       "...           ...             ...           ...            ...            ...   \n",
       "30484      268219       18.473684      3.539254           11.0           27.0   \n",
       "30485      223087       13.428571      3.207135           11.0           18.0   \n",
       "30486      288516       21.745455      3.378681           16.0           31.0   \n",
       "30487      211323       18.972973      5.852286           11.0           31.0   \n",
       "30488      251051       24.545455      5.517038           16.0           37.0   \n",
       "\n",
       "       bicarbonate_mean  bicarbonate_sd  bicarbonate_min  bicarbonate_max  \\\n",
       "0                   NaN             NaN              NaN              NaN   \n",
       "1                   NaN             NaN              NaN              NaN   \n",
       "2             31.000000             NaN             31.0             31.0   \n",
       "3             32.000000             NaN             32.0             32.0   \n",
       "4             29.000000             NaN             29.0             29.0   \n",
       "...                 ...             ...              ...              ...   \n",
       "30484         16.552632        5.717197              7.0             24.0   \n",
       "30485         28.714286        1.496026             26.0             30.0   \n",
       "30486         21.309091        2.602511             13.0             26.0   \n",
       "30487         21.621622        5.673287              8.0             33.0   \n",
       "30488         20.053571        4.109500             12.0             29.0   \n",
       "\n",
       "       calcium_total_mean  ...  urea_nitrogen_min  urea_nitrogen_max  \\\n",
       "0                8.700000  ...                NaN                NaN   \n",
       "1                9.200000  ...                NaN                NaN   \n",
       "2                7.200000  ...               15.0               15.0   \n",
       "3                9.100000  ...               27.0               27.0   \n",
       "4                8.800000  ...               22.0               22.0   \n",
       "...                   ...  ...                ...                ...   \n",
       "30484            7.582143  ...               31.0              126.0   \n",
       "30485            8.514286  ...               39.0               97.0   \n",
       "30486            8.477083  ...               34.0              146.0   \n",
       "30487            9.229032  ...               19.0              104.0   \n",
       "30488            8.577778  ...               29.0              142.0   \n",
       "\n",
       "       white_blood_cells_mean  white_blood_cells_sd  white_blood_cells_min  \\\n",
       "0                   13.600000                   NaN                   13.6   \n",
       "1                         NaN                   NaN                    NaN   \n",
       "2                   10.000000                   NaN                   10.0   \n",
       "3                    4.800000                   NaN                    4.8   \n",
       "4                   15.200000                   NaN                   15.2   \n",
       "...                       ...                   ...                    ...   \n",
       "30484               19.989744             12.016125                    6.6   \n",
       "30485                5.000000              1.272792                    4.1   \n",
       "30486               15.687755              6.906357                    8.3   \n",
       "30487                7.058621              2.703373                    1.7   \n",
       "30488               16.906522              6.435506                    7.5   \n",
       "\n",
       "       white_blood_cells_max  age  gender  icu_los_hours  target  \n",
       "0                       13.6   67       M             12       1  \n",
       "1                        NaN  300       F             14       0  \n",
       "2                       10.0   45       M             28       0  \n",
       "3                        4.8   85       M             22       0  \n",
       "4                       15.2   34       F             23       0  \n",
       "...                      ...  ...     ...            ...     ...  \n",
       "30484                   45.1   70       F            596       0  \n",
       "30485                    5.9  300       M             40       0  \n",
       "30486                   37.7   54       M            939       0  \n",
       "30487                   12.9   56       M            287       0  \n",
       "30488                   31.9   32       M            915       0  \n",
       "\n",
       "[30489 rows x 97 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_data = pd.read_csv('cohort_data_new.csv')\n",
    "cohort_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c93061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>anion_gap_mean</th>\n",
       "      <th>anion_gap_sd</th>\n",
       "      <th>anion_gap_min</th>\n",
       "      <th>anion_gap_max</th>\n",
       "      <th>bicarbonate_mean</th>\n",
       "      <th>bicarbonate_sd</th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>bicarbonate_max</th>\n",
       "      <th>calcium_total_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>urea_nitrogen_min</th>\n",
       "      <th>urea_nitrogen_max</th>\n",
       "      <th>white_blood_cells_mean</th>\n",
       "      <th>white_blood_cells_sd</th>\n",
       "      <th>white_blood_cells_min</th>\n",
       "      <th>white_blood_cells_max</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>icu_los_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>203782</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.450000</td>\n",
       "      <td>0.636396</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>82</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>228783</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>9.350000</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>72</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>254423</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.150000</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.650000</td>\n",
       "      <td>2.474874</td>\n",
       "      <td>7.9</td>\n",
       "      <td>11.4</td>\n",
       "      <td>82</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>227097</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>2.081666</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>300</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>210259</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.150000</td>\n",
       "      <td>1.909188</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30483</th>\n",
       "      <td>224190</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>1.258306</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.160247</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.450925</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>78</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30484</th>\n",
       "      <td>268219</td>\n",
       "      <td>18.473684</td>\n",
       "      <td>3.539254</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.552632</td>\n",
       "      <td>5.717197</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.582143</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>19.989744</td>\n",
       "      <td>12.016125</td>\n",
       "      <td>6.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "      <td>596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>288516</td>\n",
       "      <td>21.745455</td>\n",
       "      <td>3.378681</td>\n",
       "      <td>16.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.309091</td>\n",
       "      <td>2.602511</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.477083</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>15.687755</td>\n",
       "      <td>6.906357</td>\n",
       "      <td>8.3</td>\n",
       "      <td>37.7</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>211323</td>\n",
       "      <td>18.972973</td>\n",
       "      <td>5.852286</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.621622</td>\n",
       "      <td>5.673287</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.229032</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>7.058621</td>\n",
       "      <td>2.703373</td>\n",
       "      <td>1.7</td>\n",
       "      <td>12.9</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>251051</td>\n",
       "      <td>24.545455</td>\n",
       "      <td>5.517038</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.053571</td>\n",
       "      <td>4.109500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.577778</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>16.906522</td>\n",
       "      <td>6.435506</td>\n",
       "      <td>7.5</td>\n",
       "      <td>31.9</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13964 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       icustay_id  anion_gap_mean  anion_gap_sd  anion_gap_min  anion_gap_max  \\\n",
       "400        203782       10.000000      2.828427            8.0           12.0   \n",
       "401        228783       18.500000      0.707107           18.0           19.0   \n",
       "402        254423       17.500000      0.707107           17.0           18.0   \n",
       "403        227097       19.333333      2.081666           17.0           21.0   \n",
       "404        210259       14.000000      0.000000           14.0           14.0   \n",
       "...           ...             ...           ...            ...            ...   \n",
       "30483      224190       13.250000      1.258306           12.0           15.0   \n",
       "30484      268219       18.473684      3.539254           11.0           27.0   \n",
       "30486      288516       21.745455      3.378681           16.0           31.0   \n",
       "30487      211323       18.972973      5.852286           11.0           31.0   \n",
       "30488      251051       24.545455      5.517038           16.0           37.0   \n",
       "\n",
       "       bicarbonate_mean  bicarbonate_sd  bicarbonate_min  bicarbonate_max  \\\n",
       "400           19.000000        0.000000             19.0             19.0   \n",
       "401           19.500000        0.707107             19.0             20.0   \n",
       "402           26.500000        0.707107             26.0             27.0   \n",
       "403           18.666667        1.154701             18.0             20.0   \n",
       "404           19.000000        0.000000             19.0             19.0   \n",
       "...                 ...             ...              ...              ...   \n",
       "30483         22.000000        2.160247             20.0             25.0   \n",
       "30484         16.552632        5.717197              7.0             24.0   \n",
       "30486         21.309091        2.602511             13.0             26.0   \n",
       "30487         21.621622        5.673287              8.0             33.0   \n",
       "30488         20.053571        4.109500             12.0             29.0   \n",
       "\n",
       "       calcium_total_mean  ...  urea_nitrogen_min  urea_nitrogen_max  \\\n",
       "400              8.000000  ...               35.0               35.0   \n",
       "401              8.000000  ...               68.0               69.0   \n",
       "402              9.150000  ...               41.0               44.0   \n",
       "403              7.500000  ...               52.0               57.0   \n",
       "404              7.900000  ...               22.0               23.0   \n",
       "...                   ...  ...                ...                ...   \n",
       "30483            7.600000  ...               26.0               44.0   \n",
       "30484            7.582143  ...               31.0              126.0   \n",
       "30486            8.477083  ...               34.0              146.0   \n",
       "30487            9.229032  ...               19.0              104.0   \n",
       "30488            8.577778  ...               29.0              142.0   \n",
       "\n",
       "       white_blood_cells_mean  white_blood_cells_sd  white_blood_cells_min  \\\n",
       "400                 14.450000              0.636396                   14.0   \n",
       "401                  9.350000              0.070711                    9.3   \n",
       "402                  9.650000              2.474874                    7.9   \n",
       "403                 13.000000              0.000000                   13.0   \n",
       "404                 12.150000              1.909188                   10.8   \n",
       "...                       ...                   ...                    ...   \n",
       "30483                9.666667              0.450925                    9.2   \n",
       "30484               19.989744             12.016125                    6.6   \n",
       "30486               15.687755              6.906357                    8.3   \n",
       "30487                7.058621              2.703373                    1.7   \n",
       "30488               16.906522              6.435506                    7.5   \n",
       "\n",
       "       white_blood_cells_max  age  gender  icu_los_hours  target  \n",
       "400                     14.9   82       M             22       0  \n",
       "401                      9.4   72       M             27       0  \n",
       "402                     11.4   82       F             26       0  \n",
       "403                     13.0  300       F             39       0  \n",
       "404                     13.5   51       F             21       0  \n",
       "...                      ...  ...     ...            ...     ...  \n",
       "30483                   10.1   78       M             34       0  \n",
       "30484                   45.1   70       F            596       0  \n",
       "30486                   37.7   54       M            939       0  \n",
       "30487                   12.9   56       M            287       0  \n",
       "30488                   31.9   32       M            915       0  \n",
       "\n",
       "[13964 rows x 89 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data available in most of the patients:\n",
    "# This will drop the patients missing this vital information:\n",
    "df = cohort_data.dropna(subset=[\n",
    "    'anion_gap_mean', 'anion_gap_min', 'anion_gap_max', 'anion_gap_sd',\n",
    "    'bicarbonate_mean', 'bicarbonate_min', 'bicarbonate_max', 'bicarbonate_sd',\n",
    "    'calcium_total_mean', 'calcium_total_min', 'calcium_total_max', 'calcium_total_sd',\n",
    "    'chloride_mean', 'chloride_min', 'chloride_max', 'chloride_sd',\n",
    "    'creatinine_mean', 'creatinine_min', 'creatinine_max', 'creatinine_sd',\n",
    "    'glucose_mean', 'glucose_min', 'glucose_max', 'glucose_sd',\n",
    "    'hematocrit_mean', 'hematocrit_min', 'hematocrit_max', 'hematocrit_sd',\n",
    "    'hemoglobin_mean', 'hemoglobin_min', 'hemoglobin_max', 'hemoglobin_sd',\n",
    "    'mchc_mean', 'mchc_min', 'mchc_max', 'mchc_sd',\n",
    "    'mcv_mean', 'mcv_min', 'mcv_max', 'mcv_sd',\n",
    "    'magnesium_mean', 'magnesium_min', 'magnesium_max', 'magnesium_sd',\n",
    "    'pt_mean', 'pt_min', 'pt_max', 'pt_sd',\n",
    "    'phosphate_mean', 'phosphate_min', 'phosphate_max', 'phosphate_sd',\n",
    "    'platelet_count_mean', 'platelet_count_min', 'platelet_count_max', 'platelet_count_sd',\n",
    "    'potassium_mean', 'potassium_min', 'potassium_max', 'potassium_sd',\n",
    "    'rdw_mean', 'rdw_min', 'rdw_max', 'rdw_sd',\n",
    "    'red_blood_cells_mean', 'red_blood_cells_min', 'red_blood_cells_max', 'red_blood_cells_sd',\n",
    "    'sodium_mean', 'sodium_min', 'sodium_max', 'sodium_sd',\n",
    "    'urea_nitrogen_mean', 'urea_nitrogen_min', 'urea_nitrogen_max', 'urea_nitrogen_sd',\n",
    "    'white_blood_cells_mean', 'white_blood_cells_min', 'white_blood_cells_max', 'white_blood_cells_sd',\n",
    "    'age',  'gender', 'icu_los_hours', 'target'\n",
    "    ])\n",
    "\n",
    "# # Drop sparse columns (missing values for many ICU entries)\n",
    "df = df.dropna(axis=1, how='any')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bce19c",
   "metadata": {},
   "source": [
    "Summary of the filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6abf766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13964 entries, 400 to 30488\n",
      "Data columns (total 89 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   icustay_id              13964 non-null  int64  \n",
      " 1   anion_gap_mean          13964 non-null  float64\n",
      " 2   anion_gap_sd            13964 non-null  float64\n",
      " 3   anion_gap_min           13964 non-null  float64\n",
      " 4   anion_gap_max           13964 non-null  float64\n",
      " 5   bicarbonate_mean        13964 non-null  float64\n",
      " 6   bicarbonate_sd          13964 non-null  float64\n",
      " 7   bicarbonate_min         13964 non-null  float64\n",
      " 8   bicarbonate_max         13964 non-null  float64\n",
      " 9   calcium_total_mean      13964 non-null  float64\n",
      " 10  calcium_total_sd        13964 non-null  float64\n",
      " 11  calcium_total_min       13964 non-null  float64\n",
      " 12  calcium_total_max       13964 non-null  float64\n",
      " 13  chloride_mean           13964 non-null  float64\n",
      " 14  chloride_sd             13964 non-null  float64\n",
      " 15  chloride_min            13964 non-null  float64\n",
      " 16  chloride_max            13964 non-null  float64\n",
      " 17  creatinine_mean         13964 non-null  float64\n",
      " 18  creatinine_sd           13964 non-null  float64\n",
      " 19  creatinine_min          13964 non-null  float64\n",
      " 20  creatinine_max          13964 non-null  float64\n",
      " 21  glucose_mean            13964 non-null  float64\n",
      " 22  glucose_sd              13964 non-null  float64\n",
      " 23  glucose_min             13964 non-null  float64\n",
      " 24  glucose_max             13964 non-null  float64\n",
      " 25  hematocrit_mean         13964 non-null  float64\n",
      " 26  hematocrit_sd           13964 non-null  float64\n",
      " 27  hematocrit_min          13964 non-null  float64\n",
      " 28  hematocrit_max          13964 non-null  float64\n",
      " 29  hemoglobin_mean         13964 non-null  float64\n",
      " 30  hemoglobin_sd           13964 non-null  float64\n",
      " 31  hemoglobin_min          13964 non-null  float64\n",
      " 32  hemoglobin_max          13964 non-null  float64\n",
      " 33  mchc_mean               13964 non-null  float64\n",
      " 34  mchc_sd                 13964 non-null  float64\n",
      " 35  mchc_min                13964 non-null  float64\n",
      " 36  mchc_max                13964 non-null  float64\n",
      " 37  mch_mean                13964 non-null  float64\n",
      " 38  mch_sd                  13964 non-null  float64\n",
      " 39  mch_min                 13964 non-null  float64\n",
      " 40  mch_max                 13964 non-null  float64\n",
      " 41  mcv_mean                13964 non-null  float64\n",
      " 42  mcv_sd                  13964 non-null  float64\n",
      " 43  mcv_min                 13964 non-null  float64\n",
      " 44  mcv_max                 13964 non-null  float64\n",
      " 45  magnesium_mean          13964 non-null  float64\n",
      " 46  magnesium_sd            13964 non-null  float64\n",
      " 47  magnesium_min           13964 non-null  float64\n",
      " 48  magnesium_max           13964 non-null  float64\n",
      " 49  pt_mean                 13964 non-null  float64\n",
      " 50  pt_sd                   13964 non-null  float64\n",
      " 51  pt_min                  13964 non-null  float64\n",
      " 52  pt_max                  13964 non-null  float64\n",
      " 53  phosphate_mean          13964 non-null  float64\n",
      " 54  phosphate_sd            13964 non-null  float64\n",
      " 55  phosphate_min           13964 non-null  float64\n",
      " 56  phosphate_max           13964 non-null  float64\n",
      " 57  platelet_count_mean     13964 non-null  float64\n",
      " 58  platelet_count_sd       13964 non-null  float64\n",
      " 59  platelet_count_min      13964 non-null  float64\n",
      " 60  platelet_count_max      13964 non-null  float64\n",
      " 61  potassium_mean          13964 non-null  float64\n",
      " 62  potassium_sd            13964 non-null  float64\n",
      " 63  potassium_min           13964 non-null  float64\n",
      " 64  potassium_max           13964 non-null  float64\n",
      " 65  rdw_mean                13964 non-null  float64\n",
      " 66  rdw_sd                  13964 non-null  float64\n",
      " 67  rdw_min                 13964 non-null  float64\n",
      " 68  rdw_max                 13964 non-null  float64\n",
      " 69  red_blood_cells_mean    13964 non-null  float64\n",
      " 70  red_blood_cells_sd      13964 non-null  float64\n",
      " 71  red_blood_cells_min     13964 non-null  float64\n",
      " 72  red_blood_cells_max     13964 non-null  float64\n",
      " 73  sodium_mean             13964 non-null  float64\n",
      " 74  sodium_sd               13964 non-null  float64\n",
      " 75  sodium_min              13964 non-null  float64\n",
      " 76  sodium_max              13964 non-null  float64\n",
      " 77  urea_nitrogen_mean      13964 non-null  float64\n",
      " 78  urea_nitrogen_sd        13964 non-null  float64\n",
      " 79  urea_nitrogen_min       13964 non-null  float64\n",
      " 80  urea_nitrogen_max       13964 non-null  float64\n",
      " 81  white_blood_cells_mean  13964 non-null  float64\n",
      " 82  white_blood_cells_sd    13964 non-null  float64\n",
      " 83  white_blood_cells_min   13964 non-null  float64\n",
      " 84  white_blood_cells_max   13964 non-null  float64\n",
      " 85  age                     13964 non-null  int64  \n",
      " 86  gender                  13964 non-null  object \n",
      " 87  icu_los_hours           13964 non-null  int64  \n",
      " 88  target                  13964 non-null  int64  \n",
      "dtypes: float64(84), int64(4), object(1)\n",
      "memory usage: 9.6+ MB\n",
      "None\n",
      "          icustay_id  anion_gap_mean  anion_gap_sd  anion_gap_min  \\\n",
      "count   13964.000000    13964.000000  13964.000000   13964.000000   \n",
      "mean   250333.558794       13.064858      1.935230      10.652105   \n",
      "std     28852.413306        2.612590      1.056908       2.696492   \n",
      "min    200003.000000        3.000000      0.000000      -4.000000   \n",
      "25%    225311.750000       11.333333      1.290994       9.000000   \n",
      "50%    250548.000000       12.800000      1.812654      10.000000   \n",
      "75%    275335.500000       14.344351      2.428992      12.000000   \n",
      "max    299998.000000       28.625000     16.462078      27.000000   \n",
      "\n",
      "       anion_gap_max  bicarbonate_mean  bicarbonate_sd  bicarbonate_min  \\\n",
      "count   13964.000000      13964.000000    13964.000000     13964.000000   \n",
      "mean       15.882627         24.821454        2.290240        21.655543   \n",
      "std         3.843018          3.737576        1.329809         4.264085   \n",
      "min         4.000000          8.333333        0.000000         5.000000   \n",
      "25%        13.000000         22.666667        1.394433        19.000000   \n",
      "50%        15.000000         24.800000        2.097618        22.000000   \n",
      "75%        18.000000         26.888889        3.020106        24.000000   \n",
      "max        55.000000         48.000000       10.739336        46.000000   \n",
      "\n",
      "       bicarbonate_max  calcium_total_mean  ...  urea_nitrogen_sd  \\\n",
      "count     13964.000000        13964.000000  ...      13964.000000   \n",
      "mean         27.886207            8.291916  ...          5.428659   \n",
      "std           4.528868            0.616695  ...          5.841282   \n",
      "min           9.000000            5.062500  ...          0.000000   \n",
      "25%          25.000000            7.900000  ...          2.052279   \n",
      "50%          28.000000            8.275000  ...          3.535534   \n",
      "75%          30.000000            8.650000  ...          6.512881   \n",
      "max          50.000000           18.100000  ...         70.041704   \n",
      "\n",
      "       urea_nitrogen_min  urea_nitrogen_max  white_blood_cells_mean  \\\n",
      "count       13964.000000       13964.000000            13964.000000   \n",
      "mean           18.984030          33.794185               11.747823   \n",
      "std            15.684349          26.322637                7.078042   \n",
      "min             0.000000           2.000000                0.100000   \n",
      "25%             9.000000          16.000000                8.433333   \n",
      "50%            14.000000          25.000000               10.900000   \n",
      "75%            23.000000          42.000000               13.833333   \n",
      "max           184.000000         266.000000              464.620000   \n",
      "\n",
      "       white_blood_cells_sd  white_blood_cells_min  white_blood_cells_max  \\\n",
      "count          13964.000000           13964.000000           13964.000000   \n",
      "mean               2.584616               8.720381              15.713445   \n",
      "std                2.590185               5.791629              10.886970   \n",
      "min                0.000000               0.100000               0.100000   \n",
      "25%                1.193035               6.100000              10.400000   \n",
      "50%                2.081866               8.100000              14.000000   \n",
      "75%                3.307736              10.500000              18.800000   \n",
      "max               88.223885             394.900000             572.500000   \n",
      "\n",
      "                age  icu_los_hours        target  \n",
      "count  13964.000000   13964.000000  13964.000000  \n",
      "mean      74.650602     146.579991      0.134059  \n",
      "std       53.442056     169.572469      0.340728  \n",
      "min       18.000000      10.000000      0.000000  \n",
      "25%       53.000000      53.000000      0.000000  \n",
      "50%       67.000000      89.000000      0.000000  \n",
      "75%       79.000000     167.000000      0.000000  \n",
      "max      307.000000    3694.000000      1.000000  \n",
      "\n",
      "[8 rows x 88 columns]\n",
      "       gender\n",
      "count   13964\n",
      "unique      2\n",
      "top         M\n",
      "freq     7867\n"
     ]
    }
   ],
   "source": [
    "print(df.info())        # Data types and non-null counts\n",
    "print(df.describe())    # Summary stats for numeric columns\n",
    "print(df.describe(include='object')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9b8a40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anion_gap_mean</th>\n",
       "      <th>anion_gap_sd</th>\n",
       "      <th>anion_gap_min</th>\n",
       "      <th>anion_gap_max</th>\n",
       "      <th>bicarbonate_mean</th>\n",
       "      <th>bicarbonate_sd</th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>bicarbonate_max</th>\n",
       "      <th>calcium_total_mean</th>\n",
       "      <th>calcium_total_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>urea_nitrogen_sd</th>\n",
       "      <th>urea_nitrogen_min</th>\n",
       "      <th>urea_nitrogen_max</th>\n",
       "      <th>white_blood_cells_mean</th>\n",
       "      <th>white_blood_cells_sd</th>\n",
       "      <th>white_blood_cells_min</th>\n",
       "      <th>white_blood_cells_max</th>\n",
       "      <th>age</th>\n",
       "      <th>icu_los_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.450000</td>\n",
       "      <td>0.636396</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>68.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>9.350000</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>72</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.150000</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>...</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.650000</td>\n",
       "      <td>2.474874</td>\n",
       "      <td>7.9</td>\n",
       "      <td>11.4</td>\n",
       "      <td>82</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>19.333333</td>\n",
       "      <td>2.081666</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>...</td>\n",
       "      <td>2.516611</td>\n",
       "      <td>52.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>300</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.150000</td>\n",
       "      <td>1.909188</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30483</th>\n",
       "      <td>13.250000</td>\n",
       "      <td>1.258306</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.160247</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.745967</td>\n",
       "      <td>26.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.450925</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30484</th>\n",
       "      <td>18.473684</td>\n",
       "      <td>3.539254</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.552632</td>\n",
       "      <td>5.717197</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.582143</td>\n",
       "      <td>0.432095</td>\n",
       "      <td>...</td>\n",
       "      <td>35.602276</td>\n",
       "      <td>31.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>19.989744</td>\n",
       "      <td>12.016125</td>\n",
       "      <td>6.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>70</td>\n",
       "      <td>596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>21.745455</td>\n",
       "      <td>3.378681</td>\n",
       "      <td>16.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.309091</td>\n",
       "      <td>2.602511</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.477083</td>\n",
       "      <td>0.725593</td>\n",
       "      <td>...</td>\n",
       "      <td>36.168359</td>\n",
       "      <td>34.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>15.687755</td>\n",
       "      <td>6.906357</td>\n",
       "      <td>8.3</td>\n",
       "      <td>37.7</td>\n",
       "      <td>54</td>\n",
       "      <td>939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>18.972973</td>\n",
       "      <td>5.852286</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.621622</td>\n",
       "      <td>5.673287</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.229032</td>\n",
       "      <td>1.364354</td>\n",
       "      <td>...</td>\n",
       "      <td>28.036689</td>\n",
       "      <td>19.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>7.058621</td>\n",
       "      <td>2.703373</td>\n",
       "      <td>1.7</td>\n",
       "      <td>12.9</td>\n",
       "      <td>56</td>\n",
       "      <td>287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>24.545455</td>\n",
       "      <td>5.517038</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.053571</td>\n",
       "      <td>4.109500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.577778</td>\n",
       "      <td>0.441552</td>\n",
       "      <td>...</td>\n",
       "      <td>25.796601</td>\n",
       "      <td>29.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>16.906522</td>\n",
       "      <td>6.435506</td>\n",
       "      <td>7.5</td>\n",
       "      <td>31.9</td>\n",
       "      <td>32</td>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13964 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       anion_gap_mean  anion_gap_sd  anion_gap_min  anion_gap_max  \\\n",
       "400         10.000000      2.828427            8.0           12.0   \n",
       "401         18.500000      0.707107           18.0           19.0   \n",
       "402         17.500000      0.707107           17.0           18.0   \n",
       "403         19.333333      2.081666           17.0           21.0   \n",
       "404         14.000000      0.000000           14.0           14.0   \n",
       "...               ...           ...            ...            ...   \n",
       "30483       13.250000      1.258306           12.0           15.0   \n",
       "30484       18.473684      3.539254           11.0           27.0   \n",
       "30486       21.745455      3.378681           16.0           31.0   \n",
       "30487       18.972973      5.852286           11.0           31.0   \n",
       "30488       24.545455      5.517038           16.0           37.0   \n",
       "\n",
       "       bicarbonate_mean  bicarbonate_sd  bicarbonate_min  bicarbonate_max  \\\n",
       "400           19.000000        0.000000             19.0             19.0   \n",
       "401           19.500000        0.707107             19.0             20.0   \n",
       "402           26.500000        0.707107             26.0             27.0   \n",
       "403           18.666667        1.154701             18.0             20.0   \n",
       "404           19.000000        0.000000             19.0             19.0   \n",
       "...                 ...             ...              ...              ...   \n",
       "30483         22.000000        2.160247             20.0             25.0   \n",
       "30484         16.552632        5.717197              7.0             24.0   \n",
       "30486         21.309091        2.602511             13.0             26.0   \n",
       "30487         21.621622        5.673287              8.0             33.0   \n",
       "30488         20.053571        4.109500             12.0             29.0   \n",
       "\n",
       "       calcium_total_mean  calcium_total_sd  ...  urea_nitrogen_sd  \\\n",
       "400              8.000000          0.141421  ...          0.000000   \n",
       "401              8.000000          0.000000  ...          0.707107   \n",
       "402              9.150000          0.070711  ...          2.121320   \n",
       "403              7.500000          0.141421  ...          2.516611   \n",
       "404              7.900000          0.000000  ...          0.707107   \n",
       "...                   ...               ...  ...               ...   \n",
       "30483            7.600000          0.100000  ...          7.745967   \n",
       "30484            7.582143          0.432095  ...         35.602276   \n",
       "30486            8.477083          0.725593  ...         36.168359   \n",
       "30487            9.229032          1.364354  ...         28.036689   \n",
       "30488            8.577778          0.441552  ...         25.796601   \n",
       "\n",
       "       urea_nitrogen_min  urea_nitrogen_max  white_blood_cells_mean  \\\n",
       "400                 35.0               35.0               14.450000   \n",
       "401                 68.0               69.0                9.350000   \n",
       "402                 41.0               44.0                9.650000   \n",
       "403                 52.0               57.0               13.000000   \n",
       "404                 22.0               23.0               12.150000   \n",
       "...                  ...                ...                     ...   \n",
       "30483               26.0               44.0                9.666667   \n",
       "30484               31.0              126.0               19.989744   \n",
       "30486               34.0              146.0               15.687755   \n",
       "30487               19.0              104.0                7.058621   \n",
       "30488               29.0              142.0               16.906522   \n",
       "\n",
       "       white_blood_cells_sd  white_blood_cells_min  white_blood_cells_max  \\\n",
       "400                0.636396                   14.0                   14.9   \n",
       "401                0.070711                    9.3                    9.4   \n",
       "402                2.474874                    7.9                   11.4   \n",
       "403                0.000000                   13.0                   13.0   \n",
       "404                1.909188                   10.8                   13.5   \n",
       "...                     ...                    ...                    ...   \n",
       "30483              0.450925                    9.2                   10.1   \n",
       "30484             12.016125                    6.6                   45.1   \n",
       "30486              6.906357                    8.3                   37.7   \n",
       "30487              2.703373                    1.7                   12.9   \n",
       "30488              6.435506                    7.5                   31.9   \n",
       "\n",
       "       age  icu_los_hours  target  \n",
       "400     82             22       0  \n",
       "401     72             27       0  \n",
       "402     82             26       0  \n",
       "403    300             39       0  \n",
       "404     51             21       0  \n",
       "...    ...            ...     ...  \n",
       "30483   78             34       0  \n",
       "30484   70            596       0  \n",
       "30486   54            939       0  \n",
       "30487   56            287       0  \n",
       "30488   32            915       0  \n",
       "\n",
       "[13964 rows x 87 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('icustay_id', axis=1)\n",
    "df = df.drop('gender', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b01075f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13964, 87)\n",
      "(13964, 86)\n",
      "(13964,)\n",
      "(9774, 86)\n",
      "(4190, 86)\n",
      "(9774,)\n",
      "(4190,)\n",
      "% Readmissions in Train: 14.027010435850215\n",
      "% Readmissions in Test: 11.957040572792362\n"
     ]
    }
   ],
   "source": [
    "dataset = np.array(df)\n",
    "y = np.array(df['target'])\n",
    "X = np.array(df.drop('target', axis=1))\n",
    "print(np.shape(dataset))\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))\n",
    "\n",
    "# Random shuffle and split 70-30 into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))\n",
    "print(f'% Readmissions in Train: {np.mean(y_train) * 100}')\n",
    "print(f'% Readmissions in Test: {np.mean(y_test) * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6d10c9",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0a9f55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:16:43,138] A new study created in memory with name: no-name-8684da84-e968-4e99-a7b9-29b07317fc64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d857bf78ff64be2a5f2309748892e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:43] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:48] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:49] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:50] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:16:52,688] Trial 0 finished with value: 0.6774409922224773 and parameters: {'learning_rate': 0.01250331001543945, 'max_depth': 10, 'max_delta_step': 4, 'max_leaves': 4, 'min_child_weight': 6.456232181430629, 'n_estimators': 682, 'alpha': 0.4346791939075747, 'lambda': 1.2687132500980753, 'scale_pos_weight': 0.8541608132425591, 'subsample': 0.9897997300994384}. Best is trial 0 with value: 0.6774409922224773.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:52] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:54] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:55] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:58] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:03] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:07] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:17:09,776] Trial 1 finished with value: 0.6788829343313794 and parameters: {'learning_rate': 0.039760682577662444, 'max_depth': 9, 'max_delta_step': 5, 'max_leaves': 4, 'min_child_weight': 2.37463831194187, 'n_estimators': 817, 'alpha': 0.3181256942236034, 'lambda': 1.25254872668324, 'scale_pos_weight': 1.3110181408002357, 'subsample': 0.9008305830079517}. Best is trial 1 with value: 0.6788829343313794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:09] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:13] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:15] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:17] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:18] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:20] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:22] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:24] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:25] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:17:27,526] Trial 2 finished with value: 0.6747898422257594 and parameters: {'learning_rate': 0.09027408151278808, 'max_depth': 6, 'max_delta_step': 0, 'max_leaves': 9, 'min_child_weight': 3.111073591668486, 'n_estimators': 605, 'alpha': 0.8717733066174138, 'lambda': 1.2877788303386297, 'scale_pos_weight': 1.349307324174672, 'subsample': 0.9794281769152999}. Best is trial 1 with value: 0.6788829343313794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:29] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:31] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:33] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:34] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:36] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:38] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:40] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:42] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:17:46,154] Trial 3 finished with value: 0.6864581965890834 and parameters: {'learning_rate': 0.012962741620244706, 'max_depth': 11, 'max_delta_step': 2, 'max_leaves': 8, 'min_child_weight': 6.010620296479998, 'n_estimators': 755, 'alpha': 0.3273100266908442, 'lambda': 1.430609262293273, 'scale_pos_weight': 0.8875982893562331, 'subsample': 0.7154407987537261}. Best is trial 3 with value: 0.6864581965890834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:48] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:49] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:50] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:52] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:53] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:54] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:55] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:17:56,844] Trial 4 finished with value: 0.6824247842683598 and parameters: {'learning_rate': 0.020779468111306522, 'max_depth': 12, 'max_delta_step': 1, 'max_leaves': 8, 'min_child_weight': 4.878211018624603, 'n_estimators': 435, 'alpha': 0.4874215174602171, 'lambda': 1.2243100189187586, 'scale_pos_weight': 1.4709699903899263, 'subsample': 0.7366733458174273}. Best is trial 3 with value: 0.6864581965890834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:58] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:59] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:04] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:07] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:08] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:09] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:18:11,269] Trial 5 finished with value: 0.6846477614721819 and parameters: {'learning_rate': 0.018212046620550208, 'max_depth': 10, 'max_delta_step': 5, 'max_leaves': 9, 'min_child_weight': 1.46565483615348, 'n_estimators': 477, 'alpha': 0.5896753757268361, 'lambda': 0.9983208182892922, 'scale_pos_weight': 0.7419172784488272, 'subsample': 0.8811671691551128}. Best is trial 3 with value: 0.6864581965890834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:11] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:14] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:15] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:17] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:18] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:20] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:21] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:23] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:24] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:18:26,392] Trial 6 finished with value: 0.6816988324916922 and parameters: {'learning_rate': 0.015202923080984875, 'max_depth': 7, 'max_delta_step': 3, 'max_leaves': 9, 'min_child_weight': 5.333461290299137, 'n_estimators': 517, 'alpha': 0.643818924966115, 'lambda': 0.9104178894465504, 'scale_pos_weight': 0.8550218769414866, 'subsample': 0.9738388228365443}. Best is trial 3 with value: 0.6864581965890834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:26] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:28] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:30] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:32] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:34] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:36] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:39] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:41] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:43] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:18:47,162] Trial 7 finished with value: 0.6846676131643405 and parameters: {'learning_rate': 0.01132351638392629, 'max_depth': 6, 'max_delta_step': 2, 'max_leaves': 9, 'min_child_weight': 6.218433191284497, 'n_estimators': 727, 'alpha': 0.13174335652197058, 'lambda': 0.8201074718406658, 'scale_pos_weight': 1.051957596534793, 'subsample': 0.9107315192248906}. Best is trial 3 with value: 0.6864581965890834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:48] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:49] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:52] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:53] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:55] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:59] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:19:00,445] Trial 8 finished with value: 0.6779867157140929 and parameters: {'learning_rate': 0.03965537321649591, 'max_depth': 9, 'max_delta_step': 5, 'max_leaves': 4, 'min_child_weight': 6.45462479366382, 'n_estimators': 748, 'alpha': 0.4230635229029006, 'lambda': 1.2982533902010795, 'scale_pos_weight': 1.0189934022674825, 'subsample': 0.9678517787597908}. Best is trial 3 with value: 0.6864581965890834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:03] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:04] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:06] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:07] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:08] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:09] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:19:10,969] Trial 9 finished with value: 0.6783689961678396 and parameters: {'learning_rate': 0.014856432422840802, 'max_depth': 6, 'max_delta_step': 5, 'max_leaves': 4, 'min_child_weight': 1.6272796142214434, 'n_estimators': 584, 'alpha': 0.9616983599234089, 'lambda': 0.8522487752643214, 'scale_pos_weight': 1.0151290219392148, 'subsample': 0.7984161834192552}. Best is trial 3 with value: 0.6864581965890834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:11] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:13] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:15] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:17] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:20] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:22] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:24] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:29] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:31] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:19:33,879] Trial 10 finished with value: 0.6874859319004096 and parameters: {'learning_rate': 0.0279973887003329, 'max_depth': 4, 'max_delta_step': 2, 'max_leaves': 7, 'min_child_weight': 7.533094250265264, 'n_estimators': 1000, 'alpha': 0.11799817169651508, 'lambda': 1.4947143459496763, 'scale_pos_weight': 0.5789433796172965, 'subsample': 0.7116752004777741}. Best is trial 10 with value: 0.6874859319004096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:33] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:36] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:38] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:40] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:43] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:48] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:53] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:55] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:19:58,222] Trial 11 finished with value: 0.6871344283032097 and parameters: {'learning_rate': 0.027975462078274064, 'max_depth': 4, 'max_delta_step': 2, 'max_leaves': 7, 'min_child_weight': 7.972681207675536, 'n_estimators': 998, 'alpha': 0.1075719907490908, 'lambda': 1.4966169427326974, 'scale_pos_weight': 0.5509108974227743, 'subsample': 0.7079672859726112}. Best is trial 10 with value: 0.6874859319004096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:58] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:07] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:09] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:11] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:14] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:16] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:18] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:20:20,804] Trial 12 finished with value: 0.6883316640778888 and parameters: {'learning_rate': 0.027458484360054512, 'max_depth': 4, 'max_delta_step': 3, 'max_leaves': 6, 'min_child_weight': 7.946284330625193, 'n_estimators': 1000, 'alpha': 0.10740365418972755, 'lambda': 1.4796609022621676, 'scale_pos_weight': 0.5104372886753539, 'subsample': 0.7733951221229483}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:20] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:23] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:25] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:29] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:32] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:34] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:36] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:38] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:40] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:20:43,386] Trial 13 finished with value: 0.6759681579601412 and parameters: {'learning_rate': 0.055246498201433396, 'max_depth': 4, 'max_delta_step': 3, 'max_leaves': 6, 'min_child_weight': 7.697494774799956, 'n_estimators': 996, 'alpha': 0.2500432897036944, 'lambda': 1.4154963888921415, 'scale_pos_weight': 0.5243715312657897, 'subsample': 0.7857335615737798}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:43] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:48] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:50] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:52] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:53] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:55] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:20:56,250] Trial 14 finished with value: 0.6727074199467332 and parameters: {'learning_rate': 0.024320185333742243, 'max_depth': 4, 'max_delta_step': 1, 'max_leaves': 2, 'min_child_weight': 3.714804845383297, 'n_estimators': 886, 'alpha': 0.2209329948017248, 'lambda': 1.3931036915696746, 'scale_pos_weight': 0.7030120027104406, 'subsample': 0.7707815757768556}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:58] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:04] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:06] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:08] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:10] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:13] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:15] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:21:17,218] Trial 15 finished with value: 0.6821275028005036 and parameters: {'learning_rate': 0.03816719261195394, 'max_depth': 5, 'max_delta_step': 3, 'max_leaves': 6, 'min_child_weight': 7.223756740900795, 'n_estimators': 916, 'alpha': 0.7046720671198267, 'lambda': 1.0967583861837897, 'scale_pos_weight': 0.6494043645930506, 'subsample': 0.8293521551459264}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:17] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:19] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:21] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:23] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:25] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:29] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:31] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:33] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:36] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:21:38,043] Trial 16 finished with value: 0.6755273278616046 and parameters: {'learning_rate': 0.058971044559526904, 'max_depth': 7, 'max_delta_step': 4, 'max_leaves': 7, 'min_child_weight': 7.0539079063983445, 'n_estimators': 907, 'alpha': 0.10099588095332006, 'lambda': 1.4946972804881462, 'scale_pos_weight': 0.6236153127150622, 'subsample': 0.7517903319886466}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:38] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:39] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:41] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:43] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:49] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:52] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:54] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:21:56,446] Trial 17 finished with value: 0.6810597457524759 and parameters: {'learning_rate': 0.031796736397462666, 'max_depth': 5, 'max_delta_step': 1, 'max_leaves': 5, 'min_child_weight': 4.179126982003931, 'n_estimators': 819, 'alpha': 0.22304458922650638, 'lambda': 1.1250938667840118, 'scale_pos_weight': 1.1407100991392767, 'subsample': 0.8224317944817962}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:21:59] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:04] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:06] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:08] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:22:10,746] Trial 18 finished with value: 0.6728910176128002 and parameters: {'learning_rate': 0.05420753113260418, 'max_depth': 5, 'max_delta_step': 4, 'max_leaves': 2, 'min_child_weight': 5.344521370505768, 'n_estimators': 944, 'alpha': 0.34556130115446604, 'lambda': 1.3604477100606092, 'scale_pos_weight': 0.7832794841606687, 'subsample': 0.7453660779360421}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:10] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:14] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:16] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:19] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:21] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:24] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:26] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:28] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:30] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:22:32,959] Trial 19 finished with value: 0.6860638123356191 and parameters: {'learning_rate': 0.022038474778463, 'max_depth': 8, 'max_delta_step': 0, 'max_leaves': 6, 'min_child_weight': 7.08904409133315, 'n_estimators': 832, 'alpha': 0.728942123056509, 'lambda': 1.1848639611233982, 'scale_pos_weight': 0.5127593949642958, 'subsample': 0.8567162226580959}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:33] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:36] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:39] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:42] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:48] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:22:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:03] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:06] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:23:09,756] Trial 20 finished with value: 0.679879028265403 and parameters: {'learning_rate': 0.03231708899445092, 'max_depth': 7, 'max_delta_step': 2, 'max_leaves': 10, 'min_child_weight': 7.956553109474411, 'n_estimators': 969, 'alpha': 0.18591661037014923, 'lambda': 1.3391455891365351, 'scale_pos_weight': 0.6180168345473194, 'subsample': 0.7097918171103055}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:09] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:15] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:17] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:19] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:22] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:24] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:29] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:32] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:23:34,659] Trial 21 finished with value: 0.6871908965018767 and parameters: {'learning_rate': 0.025823550583684716, 'max_depth': 4, 'max_delta_step': 2, 'max_leaves': 7, 'min_child_weight': 7.985198793200034, 'n_estimators': 989, 'alpha': 0.11102036603702452, 'lambda': 1.4871589182756997, 'scale_pos_weight': 0.527970755219368, 'subsample': 0.701913658686419}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:34] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:37] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:39] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:41] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:43] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:49] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:53] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:23:55,569] Trial 22 finished with value: 0.6853422414288762 and parameters: {'learning_rate': 0.028338926079984412, 'max_depth': 4, 'max_delta_step': 3, 'max_leaves': 7, 'min_child_weight': 7.276880783173002, 'n_estimators': 878, 'alpha': 0.28883507457751595, 'lambda': 1.4439389372182043, 'scale_pos_weight': 0.5838477799285701, 'subsample': 0.7336277224089605}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:55] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:23:59] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:08] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:16] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:20] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:24] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:24:27,736] Trial 23 finished with value: 0.6856505462046103 and parameters: {'learning_rate': 0.017151589378071114, 'max_depth': 5, 'max_delta_step': 1, 'max_leaves': 5, 'min_child_weight': 6.771918733289832, 'n_estimators': 953, 'alpha': 0.1382766534689183, 'lambda': 1.493776856740836, 'scale_pos_weight': 0.5045937277221342, 'subsample': 0.7681371703491559}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:31] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:35] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:39] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:42] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:49] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:53] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:24:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:25:05,563] Trial 24 finished with value: 0.6870691850522788 and parameters: {'learning_rate': 0.024576263386605124, 'max_depth': 4, 'max_delta_step': 2, 'max_leaves': 8, 'min_child_weight': 5.81572799755809, 'n_estimators': 858, 'alpha': 0.17664005269728222, 'lambda': 1.3494678326264518, 'scale_pos_weight': 0.6954064593016013, 'subsample': 0.7198626521163702}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:10] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:15] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:20] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:26] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:31] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:35] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:40] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:25:50,723] Trial 25 finished with value: 0.6867629949737534 and parameters: {'learning_rate': 0.020051130382693794, 'max_depth': 5, 'max_delta_step': 3, 'max_leaves': 5, 'min_child_weight': 7.511083125438375, 'n_estimators': 999, 'alpha': 0.2535008252096486, 'lambda': 1.4444410075110705, 'scale_pos_weight': 0.7897806411278581, 'subsample': 0.7017434170549163}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:50] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:54] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:25:59] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:04] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:07] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:09] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:14] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:26:16,419] Trial 26 finished with value: 0.6839956367506801 and parameters: {'learning_rate': 0.04401020737421284, 'max_depth': 6, 'max_delta_step': 4, 'max_leaves': 7, 'min_child_weight': 7.909170396486372, 'n_estimators': 937, 'alpha': 0.41207523874330376, 'lambda': 1.0627655552166542, 'scale_pos_weight': 0.6354726614920935, 'subsample': 0.8040718710741103}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:16] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:18] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:20] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:22] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:25] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:28] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:31] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:34] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:38] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:40] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:26:43,464] Trial 27 finished with value: 0.6854863743906815 and parameters: {'learning_rate': 0.026147481577512215, 'max_depth': 4, 'max_delta_step': 2, 'max_leaves': 6, 'min_child_weight': 6.70838469476065, 'n_estimators': 799, 'alpha': 0.19109670161079517, 'lambda': 1.3816573060551494, 'scale_pos_weight': 0.92863087303891, 'subsample': 0.7578328219319201}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:43] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:48] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:54] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:26:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:08] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:27:11,150] Trial 28 finished with value: 0.6880851944926941 and parameters: {'learning_rate': 0.03340195833120764, 'max_depth': 5, 'max_delta_step': 1, 'max_leaves': 8, 'min_child_weight': 5.67927690466828, 'n_estimators': 674, 'alpha': 0.3687742956699117, 'lambda': 1.460545326048454, 'scale_pos_weight': 0.5666498890639634, 'subsample': 0.728850503657902}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:11] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:13] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:16] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:19] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:21] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:24] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:30] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:32] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:35] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:27:38,249] Trial 29 finished with value: 0.6761537886969043 and parameters: {'learning_rate': 0.04729221335802361, 'max_depth': 5, 'max_delta_step': 0, 'max_leaves': 10, 'min_child_weight': 5.5729500323959416, 'n_estimators': 658, 'alpha': 0.5077102155701216, 'lambda': 1.3323676289291881, 'scale_pos_weight': 0.7943760480976902, 'subsample': 0.7858508967026054}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:38] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:40] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:43] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:50] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:53] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:27:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:03] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:28:07,439] Trial 30 finished with value: 0.6785052680891704 and parameters: {'learning_rate': 0.06728131597769033, 'max_depth': 8, 'max_delta_step': 1, 'max_leaves': 8, 'min_child_weight': 4.8712062805778205, 'n_estimators': 659, 'alpha': 0.37800569630737546, 'lambda': 1.4391868198231026, 'scale_pos_weight': 1.1235181491939907, 'subsample': 0.7323838526972032}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:07] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:10] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:15] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:18] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:21] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:24] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:30] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:32] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:28:34,476] Trial 31 finished with value: 0.6851398355527809 and parameters: {'learning_rate': 0.03397970149880828, 'max_depth': 4, 'max_delta_step': 1, 'max_leaves': 7, 'min_child_weight': 7.529383239966682, 'n_estimators': 688, 'alpha': 0.16563536338256893, 'lambda': 1.46458037073128, 'scale_pos_weight': 0.5964759211567687, 'subsample': 0.7003054201615636}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:34] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:37] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:40] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:50] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:53] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:28:59] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:29:05,757] Trial 32 finished with value: 0.6869256854559069 and parameters: {'learning_rate': 0.03534718408020258, 'max_depth': 5, 'max_delta_step': 2, 'max_leaves': 8, 'min_child_weight': 6.663832450056657, 'n_estimators': 617, 'alpha': 0.2673606704525843, 'lambda': 1.3957907770840112, 'scale_pos_weight': 0.6890508096352856, 'subsample': 0.7273494304638535}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:08] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:10] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:13] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:15] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:17] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:20] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:22] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:25] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:29:29,834] Trial 33 finished with value: 0.6843814321834205 and parameters: {'learning_rate': 0.03023483245296031, 'max_depth': 6, 'max_delta_step': 3, 'max_leaves': 6, 'min_child_weight': 2.9438246153429066, 'n_estimators': 537, 'alpha': 0.10323467769304628, 'lambda': 1.4989578004804378, 'scale_pos_weight': 0.5652032588658832, 'subsample': 0.7583293248105355}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:29] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:34] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:38] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:43] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:52] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:29:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:10] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:30:14,640] Trial 34 finished with value: 0.6878692086663152 and parameters: {'learning_rate': 0.022642968304921608, 'max_depth': 4, 'max_delta_step': 2, 'max_leaves': 7, 'min_child_weight': 6.234188469242418, 'n_estimators': 961, 'alpha': 0.31790526861743906, 'lambda': 1.4513805707670433, 'scale_pos_weight': 0.5503539289249003, 'subsample': 0.7279440093313209}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:14] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:18] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:23] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:31] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:35] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:40] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:48] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:52] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:30:57,075] Trial 35 finished with value: 0.6857007458734526 and parameters: {'learning_rate': 0.022328995576889245, 'max_depth': 5, 'max_delta_step': 0, 'max_leaves': 5, 'min_child_weight': 6.224130241083701, 'n_estimators': 922, 'alpha': 0.3265927461221444, 'lambda': 1.2432604198051038, 'scale_pos_weight': 0.6489189878650791, 'subsample': 0.7756673737394965}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:30:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:09] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:16] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:20] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:24] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:28] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:32] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:31:36,061] Trial 36 finished with value: 0.6800958444629758 and parameters: {'learning_rate': 0.044894643282508265, 'max_depth': 4, 'max_delta_step': 1, 'max_leaves': 8, 'min_child_weight': 4.935132003787849, 'n_estimators': 774, 'alpha': 0.4599889296683645, 'lambda': 1.290032030377148, 'scale_pos_weight': 0.7266260379543185, 'subsample': 0.7411158659556253}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:36] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:39] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:42] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:48] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:54] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:31:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:03] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:32:07,068] Trial 37 finished with value: 0.6791702199506722 and parameters: {'learning_rate': 0.01851379414870528, 'max_depth': 12, 'max_delta_step': 4, 'max_leaves': 3, 'min_child_weight': 5.8682694038485925, 'n_estimators': 857, 'alpha': 0.5710026147075022, 'lambda': 1.41491886965524, 'scale_pos_weight': 1.279993331962103, 'subsample': 0.722747223527103}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:07] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:17] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:23] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:28] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:33] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:39] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:32:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:33:00,736] Trial 38 finished with value: 0.664311101224285 and parameters: {'learning_rate': 0.09880647723338834, 'max_depth': 11, 'max_delta_step': 2, 'max_leaves': 9, 'min_child_weight': 4.534288144862183, 'n_estimators': 717, 'alpha': 0.36738292954002105, 'lambda': 1.3178536837966999, 'scale_pos_weight': 0.938787912921785, 'subsample': 0.8127410308786674}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:05] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:10] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:14] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:19] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:24] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:29] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:33] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:38] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:43] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:33:47,768] Trial 39 finished with value: 0.6872482516831908 and parameters: {'learning_rate': 0.013922079478862487, 'max_depth': 6, 'max_delta_step': 3, 'max_leaves': 7, 'min_child_weight': 6.404403338299269, 'n_estimators': 962, 'alpha': 0.5250531634810183, 'lambda': 1.2025838671007423, 'scale_pos_weight': 0.5772024700100999, 'subsample': 0.8374094743543918}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:49] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:54] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:33:58] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:04] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:07] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:34:09,306] Trial 40 finished with value: 0.6824323078338936 and parameters: {'learning_rate': 0.01693092260739245, 'max_depth': 7, 'max_delta_step': 1, 'max_leaves': 8, 'min_child_weight': 6.89765326306112, 'n_estimators': 403, 'alpha': 0.3033226299609788, 'lambda': 1.4582189608982952, 'scale_pos_weight': 1.4798161016263265, 'subsample': 0.9984793928630921}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:09] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:14] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:18] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:23] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:28] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:33] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:38] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:42] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:52] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:34:56,790] Trial 41 finished with value: 0.6848661090466238 and parameters: {'learning_rate': 0.010582058682612576, 'max_depth': 6, 'max_delta_step': 3, 'max_leaves': 7, 'min_child_weight': 6.381216068502171, 'n_estimators': 966, 'alpha': 0.6264775669453646, 'lambda': 1.2036972296109218, 'scale_pos_weight': 0.5930829376472004, 'subsample': 0.9199879689415142}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:34:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:07] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:17] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:22] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:32] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:37] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:42] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:35:46,941] Trial 42 finished with value: 0.6854940070611082 and parameters: {'learning_rate': 0.013051302530384029, 'max_depth': 5, 'max_delta_step': 3, 'max_leaves': 8, 'min_child_weight': 6.031362313421547, 'n_estimators': 968, 'alpha': 0.5154297421726474, 'lambda': 1.2567523717345521, 'scale_pos_weight': 0.5722033767027912, 'subsample': 0.8731215462786804}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:52] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:35:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:07] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:18] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:23] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:28] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:33] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:36:38,431] Trial 43 finished with value: 0.6859003717161472 and parameters: {'learning_rate': 0.014450438134428296, 'max_depth': 6, 'max_delta_step': 2, 'max_leaves': 9, 'min_child_weight': 5.558070358197839, 'n_estimators': 897, 'alpha': 0.4707946336670517, 'lambda': 0.9614378395584366, 'scale_pos_weight': 0.6666270392445467, 'subsample': 0.8487087837769407}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:38] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:42] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:51] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:36:55] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:00] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:04] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:08] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:12] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:17] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:37:21,301] Trial 44 finished with value: 0.6828314774060957 and parameters: {'learning_rate': 0.02016991918597729, 'max_depth': 4, 'max_delta_step': 4, 'max_leaves': 6, 'min_child_weight': 7.485116004049026, 'n_estimators': 942, 'alpha': 0.4172095495335706, 'lambda': 1.0332002927777137, 'scale_pos_weight': 0.7640448861325508, 'subsample': 0.9547860043497127}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:21] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:24] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:30] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:33] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:36] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:39] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:41] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:37:50,757] Trial 45 finished with value: 0.6844812317886099 and parameters: {'learning_rate': 0.036406026233087155, 'max_depth': 9, 'max_delta_step': 3, 'max_leaves': 7, 'min_child_weight': 6.498262579398521, 'n_estimators': 621, 'alpha': 0.6974555045810187, 'lambda': 1.3767320626746844, 'scale_pos_weight': 0.8539778990212621, 'subsample': 0.7936085238613998}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:50] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:53] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:37:59] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:38:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:38:06] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:38:11] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:38:15] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:38:19] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:38:23] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:38:27,724] Trial 46 finished with value: 0.6843541813047067 and parameters: {'learning_rate': 0.011746727718422488, 'max_depth': 4, 'max_delta_step': 2, 'max_leaves': 7, 'min_child_weight': 7.299452838105229, 'n_estimators': 577, 'alpha': 0.7695666600500051, 'lambda': 1.4153340256193039, 'scale_pos_weight': 0.5503402330447803, 'subsample': 0.7188097094906478}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:38:27] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:38:36] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:38:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:38:57] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:39:08] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:39:18] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:39:30] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:39:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:39:55] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:40:06] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:40:15,788] Trial 47 finished with value: 0.6843666131828073 and parameters: {'learning_rate': 0.028550521088294627, 'max_depth': 5, 'max_delta_step': 3, 'max_leaves': 9, 'min_child_weight': 5.194053829024573, 'n_estimators': 978, 'alpha': 0.5498365997528823, 'lambda': 1.4649764610254512, 'scale_pos_weight': 0.5423731225440664, 'subsample': 0.7497248979694139}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:40:15] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:40:22] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:40:29] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:40:37] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:40:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:40:55] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:04] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:11] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:16] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:21] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:41:26,788] Trial 48 finished with value: 0.6868682892816413 and parameters: {'learning_rate': 0.023341657437502817, 'max_depth': 6, 'max_delta_step': 3, 'max_leaves': 6, 'min_child_weight': 6.152963988217847, 'n_estimators': 924, 'alpha': 0.21854845527758182, 'lambda': 0.9067249873330223, 'scale_pos_weight': 0.5002979086513041, 'subsample': 0.8406073338774318}. Best is trial 12 with value: 0.6883316640778888.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:26] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:30] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:34] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:38] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:42] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:49] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:52] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:56] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:41:59] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 13:42:02,888] Trial 49 finished with value: 0.682428232468151 and parameters: {'learning_rate': 0.03966869019085301, 'max_depth': 4, 'max_delta_step': 4, 'max_leaves': 6, 'min_child_weight': 1.0620338327624217, 'n_estimators': 768, 'alpha': 0.9948334000945239, 'lambda': 1.4234058199872266, 'scale_pos_weight': 1.3971750161062575, 'subsample': 0.8935243460986789}. Best is trial 12 with value: 0.6883316640778888.\n",
      "\n",
      "Best Parameters Found:\n",
      "learning_rate: 0.027458484360054512\n",
      "max_depth: 4\n",
      "max_delta_step: 3\n",
      "max_leaves: 6\n",
      "min_child_weight: 7.946284330625193\n",
      "n_estimators: 1000\n",
      "alpha: 0.10740365418972755\n",
      "lambda: 1.4796609022621676\n",
      "scale_pos_weight: 0.5104372886753539\n",
      "subsample: 0.7733951221229483\n",
      "\n",
      "Best Cross-Validation AUC: 0.6883316640778888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\miniconda3\\envs\\ML_Torch\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:42:02] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(alpha=0.10740365418972755, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              lambda=1.4796609022621676, learning_rate=0.027458484360054512,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=3, max_depth=4, max_leaves=6,\n",
       "              min_child_weight=7.946284330625193, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(alpha=0.10740365418972755, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              lambda=1.4796609022621676, learning_rate=0.027458484360054512,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=3, max_depth=4, max_leaves=6,\n",
       "              min_child_weight=7.946284330625193, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(alpha=0.10740365418972755, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              lambda=1.4796609022621676, learning_rate=0.027458484360054512,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=3, max_depth=4, max_leaves=6,\n",
       "              min_child_weight=7.946284330625193, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "RANDOM_STATE = 229\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"use_label_encoder\": False,\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"n_jobs\": -1,\n",
    "\n",
    "        # Search around your known good values\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 12),\n",
    "        \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 0, 5),\n",
    "        \"max_leaves\": trial.suggest_int(\"max_leaves\", 2, 10),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1, 8),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 1000),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 0.8, 1.5),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.5, 1.5),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "    }\n",
    "\n",
    "    aucs = []\n",
    "    for train_idx, valid_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train[train_idx], X_train[valid_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[valid_idx]\n",
    "\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        y_pred = model.predict_proba(X_val)[:, 1]\n",
    "        aucs.append(roc_auc_score(y_val, y_pred))\n",
    "\n",
    "    return np.mean(aucs)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"\\nBest Cross-Validation AUC:\", study.best_value)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_params.update({\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"use_label_encoder\": False,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"n_jobs\": -1,\n",
    "})\n",
    "\n",
    "final_model = xgb.XGBClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23065224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test ROC AUC: 0.6856\n"
     ]
    }
   ],
   "source": [
    "y_proba_test = final_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (y_proba_test >= 0.5).astype(int)\n",
    "\n",
    "test_auroc = roc_auc_score(y_test, y_proba_test)\n",
    "print(f\"\\nFinal Test ROC AUC: {test_auroc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
