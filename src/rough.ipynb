{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (30489, 97)\n",
      "Train shape: (21342, 94), Test shape: (9147, 94)\n",
      "% Readmissions in Train: 10.74\n",
      "% Readmissions in Test: 10.75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827b5bc8cdb84c788ebde81ed2b492ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_auc_score, roc_curve, auc, RocCurveDisplay\n",
    ")\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "xgb.set_config(verbosity=0)\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.rcParams.update({'text.usetex': False})\n",
    "cohort_data = pd.read_csv('cohort_data_new.csv')\n",
    "print(\"Dataset shape:\", cohort_data.shape)\n",
    "\n",
    "# Drop identifying columns\n",
    "drop_cols = [c for c in cohort_data.columns if 'icustay_id' in c.lower() or 'subject' in c.lower()]\n",
    "cohort_data = cohort_data.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Separate features and labels\n",
    "X = cohort_data.drop(columns=['target'])\n",
    "y = cohort_data['target']\n",
    "\n",
    "# Keep only numeric columns and handle infinities\n",
    "X = X.select_dtypes(include=['number']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "print(f\"% Readmissions in Train: {np.mean(y_train) * 100:.2f}\")\n",
    "print(f\"% Readmissions in Test: {np.mean(y_test) * 100:.2f}\")\n",
    "\n",
    "RANDOM_STATE = 229\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"use_label_encoder\": False,\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"n_jobs\": -1,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 12),\n",
    "        \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 0, 5),\n",
    "        \"max_leaves\": trial.suggest_int(\"max_leaves\", 2, 10),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1, 8),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 1000),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 0.8, 1.5),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.5, 1.5),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "    }\n",
    "\n",
    "    aucs = []\n",
    "    for train_idx, valid_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "        y_pred = model.predict_proba(X_val)[:, 1]\n",
    "        aucs.append(roc_auc_score(y_val, y_pred))\n",
    "\n",
    "    return np.mean(aucs)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Run Optuna optimization\n",
    "\n",
    "# %%\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(f\"\\nBest Cross-Validation AUC: {study.best_value:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Train final model on full training set\n",
    "\n",
    "# %%\n",
    "best_params = study.best_params\n",
    "best_params.update({\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"use_label_encoder\": False,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"n_jobs\": -1,\n",
    "})\n",
    "\n",
    "final_model = xgb.XGBClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Evaluate on test set\n",
    "\n",
    "# %%\n",
    "y_proba_test = final_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (y_proba_test >= 0.5).astype(int)\n",
    "\n",
    "test_auroc = roc_auc_score(y_test, y_proba_test)\n",
    "print(f\"\\nFinal Test ROC AUC: {test_auroc:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "RocCurveDisplay.from_estimator(final_model, X_test, y_test)\n",
    "plt.title(\"ROC Curve - XGBoost\")\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Feature Importance (Top 20)\n",
    "\n",
    "# %%\n",
    "importances = final_model.feature_importances_\n",
    "feat_imp = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
    "feat_imp = feat_imp.sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(y='feature', x='importance', data=feat_imp)\n",
    "plt.title(\"Top 20 Feature Importances (XGBoost)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541158f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study).show()\n",
    "optuna.visualization.plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65802e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
